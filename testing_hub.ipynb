{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7993ca06-8adc-4f25-88b0-4969617146ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn='WLASL_v0.3.json'\n",
    "# proc.CsvCorrector(\"C:/Users/Administrator/JUPYTER/kursovayz/raw_videos/*\",fn,'testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0ff99f-79ec-41cf-bf96-b77149d21cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from video_processor import process\n",
    "df_dict=pd.read_csv(\"correctec names\",dtype=str).to_dict()\n",
    "proc=process(64,64,30)\n",
    "res=[]\n",
    "\n",
    "for key in df_dict.keys():\n",
    "    if key=='go':\n",
    "        break\n",
    "    for index in df_dict[key].keys():\n",
    "        if df_dict[key][index]=='-1':\n",
    "            continue\n",
    "        path1=str(df_dict[key][index])+\".mp4\"\n",
    "        path2=str(df_dict[key][index])+\".swf\"\n",
    "        vid1=proc.VidConveter(path1,issave=True)\n",
    "        vid2=proc.VidConveter(path2,issave=True)\n",
    "        if vid1 == '-1' and vid2=='-1':            \n",
    "            print(\"Unexeptable type of video. VID:\",df_dict[key][index])\n",
    "            sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ab481a-dd7b-43ba-a038-80403e1c2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from train import x_FrameConc,y2numbers,SaveAndPlot,SaveTrainingLog\n",
    "from video_processor import process,VideoReader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "088c6723-16c2-423c-9bb0-917c3affb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h,fps=64,64,30\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "limit_class='go'\n",
    "path='corrected names.csv'\n",
    "\n",
    "_x,_y=VideoReader(path,limit_class=limit_class)\n",
    "x,frame_num=x_FrameConc(_x,w,h)\n",
    "y=y2numbers(_y)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=42,stratify=y)\n",
    "\n",
    "x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
    "x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a8b057-c3c8-436f-81ab-37e29fbde125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 137, 62, 62, 16)   1312      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 68, 31, 31, 16)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 68, 31, 31, 16)    0         \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 66, 29, 29, 32)    13856     \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 64, 27, 27, 32)    27680     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 32, 13, 13, 32)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 13, 13, 32)    0         \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 30, 11, 11, 64)    55360     \n",
      "                                                                 \n",
      " conv3d_4 (Conv3D)           (None, 28, 9, 9, 64)      110656    \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 14, 4, 4, 64)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 4, 4, 64)      0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14336)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1835136   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,044,774\n",
      "Trainable params: 2,044,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, MaxPooling3D, Conv3D, Flatten, Dropout\n",
    "\n",
    "_loss='sparse_categorical_crossentropy'\n",
    "kernel_size=(3,3,3)\n",
    "\n",
    "model3d=Sequential()\n",
    "model3d.add(Conv3D(16,kernel_size,activation='relu',input_shape=(frame_num,w,h,3)))\n",
    "model3d.add(MaxPooling3D((2,2,2)))\n",
    "model3d.add(Dropout(0.5))\n",
    "model3d.add(Conv3D(32,kernel_size,activation='relu'))\n",
    "model3d.add(Conv3D(32,kernel_size,activation='relu'))\n",
    "model3d.add(MaxPooling3D((2,2,2)))\n",
    "model3d.add(Dropout(0.5))\n",
    "model3d.add(Conv3D(64,kernel_size,activation='relu'))\n",
    "model3d.add(Conv3D(64,kernel_size,activation='relu'))\n",
    "model3d.add(MaxPooling3D((2,2,2)))\n",
    "model3d.add(Dropout(0.5))\n",
    "model3d.add(Flatten())\n",
    "model3d.add(Dense(128,activation='relu'))\n",
    "model3d.add(Dense(6,activation='softmax'))\n",
    "model3d.compile(optimizer='adam',loss=_loss,metrics=['accuracy'])\n",
    "model3d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac515b5d-8ff2-4cda-a57f-26f70051cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 - 64s - loss: 1.8112 - accuracy: 0.2121 - val_loss: 1.7520 - val_accuracy: 0.0588 - 64s/epoch - 32s/step\n",
      "Epoch 2/30\n",
      "2/2 - 58s - loss: 1.6048 - accuracy: 0.2727 - val_loss: 1.7327 - val_accuracy: 0.2353 - 58s/epoch - 29s/step\n",
      "Epoch 3/30\n",
      "2/2 - 58s - loss: 1.5331 - accuracy: 0.3030 - val_loss: 1.7516 - val_accuracy: 0.1176 - 58s/epoch - 29s/step\n",
      "Epoch 4/30\n",
      "2/2 - 59s - loss: 1.4548 - accuracy: 0.3333 - val_loss: 1.7654 - val_accuracy: 0.0000e+00 - 59s/epoch - 29s/step\n",
      "Epoch 5/30\n",
      "2/2 - 58s - loss: 1.4850 - accuracy: 0.3939 - val_loss: 1.7617 - val_accuracy: 0.0588 - 58s/epoch - 29s/step\n",
      "Epoch 6/30\n",
      "2/2 - 59s - loss: 1.4806 - accuracy: 0.3939 - val_loss: 1.7429 - val_accuracy: 0.1765 - 59s/epoch - 29s/step\n",
      "Epoch 7/30\n",
      "2/2 - 62s - loss: 1.4628 - accuracy: 0.3636 - val_loss: 1.6912 - val_accuracy: 0.2353 - 62s/epoch - 31s/step\n",
      "Epoch 8/30\n",
      "2/2 - 61s - loss: 1.3593 - accuracy: 0.3939 - val_loss: 1.6725 - val_accuracy: 0.2941 - 61s/epoch - 31s/step\n",
      "Epoch 9/30\n",
      "2/2 - 63s - loss: 1.2512 - accuracy: 0.4242 - val_loss: 1.7054 - val_accuracy: 0.1176 - 63s/epoch - 32s/step\n",
      "Epoch 10/30\n",
      "2/2 - 63s - loss: 1.2834 - accuracy: 0.4545 - val_loss: 1.7189 - val_accuracy: 0.2941 - 63s/epoch - 31s/step\n",
      "Epoch 11/30\n",
      "2/2 - 62s - loss: 1.1909 - accuracy: 0.5455 - val_loss: 1.7812 - val_accuracy: 0.1176 - 62s/epoch - 31s/step\n",
      "Epoch 12/30\n",
      "2/2 - 62s - loss: 1.4252 - accuracy: 0.4545 - val_loss: 1.9801 - val_accuracy: 0.2353 - 62s/epoch - 31s/step\n",
      "Epoch 13/30\n",
      "2/2 - 64s - loss: 1.9500 - accuracy: 0.4848 - val_loss: 1.7657 - val_accuracy: 0.2353 - 64s/epoch - 32s/step\n",
      "Epoch 14/30\n",
      "2/2 - 63s - loss: 1.4759 - accuracy: 0.4242 - val_loss: 1.7162 - val_accuracy: 0.1765 - 63s/epoch - 32s/step\n",
      "Epoch 15/30\n",
      "2/2 - 63s - loss: 1.2924 - accuracy: 0.4848 - val_loss: 1.7604 - val_accuracy: 0.0000e+00 - 63s/epoch - 31s/step\n",
      "Epoch 16/30\n",
      "2/2 - 62s - loss: 1.4416 - accuracy: 0.4848 - val_loss: 1.7727 - val_accuracy: 0.0000e+00 - 62s/epoch - 31s/step\n",
      "Epoch 17/30\n",
      "2/2 - 62s - loss: 1.4840 - accuracy: 0.4545 - val_loss: 1.7735 - val_accuracy: 0.0588 - 62s/epoch - 31s/step\n",
      "Epoch 18/30\n",
      "2/2 - 63s - loss: 1.4471 - accuracy: 0.3939 - val_loss: 1.8415 - val_accuracy: 0.0588 - 63s/epoch - 31s/step\n",
      "Epoch 19/30\n",
      "2/2 - 63s - loss: 1.6073 - accuracy: 0.3636 - val_loss: 1.8224 - val_accuracy: 0.0588 - 63s/epoch - 32s/step\n",
      "Epoch 20/30\n",
      "2/2 - 63s - loss: 1.5355 - accuracy: 0.3939 - val_loss: 1.7598 - val_accuracy: 0.0588 - 63s/epoch - 31s/step\n",
      "Epoch 21/30\n",
      "2/2 - 62s - loss: 1.4276 - accuracy: 0.3939 - val_loss: 1.7551 - val_accuracy: 0.0000e+00 - 62s/epoch - 31s/step\n",
      "Epoch 22/30\n",
      "2/2 - 62s - loss: 1.4585 - accuracy: 0.3939 - val_loss: 1.7482 - val_accuracy: 0.0000e+00 - 62s/epoch - 31s/step\n",
      "Epoch 23/30\n",
      "2/2 - 62s - loss: 1.4419 - accuracy: 0.4848 - val_loss: 1.7389 - val_accuracy: 0.0588 - 62s/epoch - 31s/step\n",
      "Epoch 24/30\n",
      "2/2 - 63s - loss: 1.4277 - accuracy: 0.4545 - val_loss: 1.7251 - val_accuracy: 0.1176 - 63s/epoch - 32s/step\n",
      "Epoch 25/30\n",
      "2/2 - 62s - loss: 1.3704 - accuracy: 0.3939 - val_loss: 1.7051 - val_accuracy: 0.2941 - 62s/epoch - 31s/step\n",
      "Epoch 26/30\n",
      "2/2 - 62s - loss: 1.3069 - accuracy: 0.3939 - val_loss: 1.6893 - val_accuracy: 0.3529 - 62s/epoch - 31s/step\n",
      "Epoch 27/30\n",
      "2/2 - 62s - loss: 1.2173 - accuracy: 0.3636 - val_loss: 1.7958 - val_accuracy: 0.3529 - 62s/epoch - 31s/step\n",
      "Epoch 28/30\n",
      "2/2 - 62s - loss: 1.2916 - accuracy: 0.3939 - val_loss: 1.9852 - val_accuracy: 0.2941 - 62s/epoch - 31s/step\n",
      "Epoch 29/30\n",
      "2/2 - 62s - loss: 1.4137 - accuracy: 0.3939 - val_loss: 1.9914 - val_accuracy: 0.2941 - 62s/epoch - 31s/step\n",
      "Epoch 30/30\n",
      "2/2 - 62s - loss: 1.3487 - accuracy: 0.3939 - val_loss: 1.9267 - val_accuracy: 0.3529 - 62s/epoch - 31s/step\n"
     ]
    }
   ],
   "source": [
    "_epochs=30\n",
    "history=model3d.fit(x_train,y_train,epochs=_epochs,validation_split=0.2)\n",
    "\n",
    "SaveTrainingLog(model3d,history)\n",
    "SaveAndPlot(history)\n",
    "\n",
    "model3d.evaluate(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
